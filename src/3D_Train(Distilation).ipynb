{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
      },
      "source": [
        "## Import"
      ],
      "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPKutxbAqrg1",
        "outputId": "32d9dc4c-bf74-44b0-8927-ccec89401803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "SPKutxbAqrg1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGSX4XJS_pRd",
        "outputId": "3c5267c1-4ab7-4582-80d8-0fad05cf9806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/shijianjian/EfficientNet-PyTorch-3D\n",
            "  Cloning https://github.com/shijianjian/EfficientNet-PyTorch-3D to /tmp/pip-req-build-445t8hu9\n",
            "  Running command git clone -q https://github.com/shijianjian/EfficientNet-PyTorch-3D /tmp/pip-req-build-445t8hu9\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch-3d==0.6.3) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch-3d==0.6.3) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/shijianjian/EfficientNet-PyTorch-3D"
      ],
      "id": "XGSX4XJS_pRd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9K8Ez9QN9AP"
      },
      "source": [],
      "id": "V9K8Ez9QN9AP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgOkVcfVMqk4",
        "outputId": "902de347-a4e8-4202-c154-9e3186fdccc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchio in /usr/local/lib/python3.7/dist-packages (0.18.84)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: SimpleITK!=2.0.*,!=2.1.1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.12.1+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.7.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/dist-packages (from torchio) (1.2.13)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.21.6)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (4.1.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchio"
      ],
      "id": "hgOkVcfVMqk4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgJWaQQKqsH-",
        "outputId": "9874700e-e0c8-49b8-d47a-2c5251afd733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/3d data\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/data/3d data\"\n",
        "#!unzip -q \"/content/drive/MyDrive/data/3d data/open.zip\""
      ],
      "id": "YgJWaQQKqsH-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCPeCcN0wMfQ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/data/3d data')"
      ],
      "id": "vCPeCcN0wMfQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
      },
      "outputs": [],
      "source": [
        "import h5py # .h5 파일을 읽기 위한 패키지\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from plotly.offline import iplot\n",
        "from utils import EarlyStopping, SAM\n",
        "from tqdm.auto import tqdm\n",
        "import torchio as tio\n",
        "from torchio.transforms import ToCanonical,ZNormalization\n",
        "from typing import Sequence, Callable\n",
        "from efficientnet_pytorch_3d import EfficientNet3D\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d13862e3-bb27-47af-9b58-a9fbf804df71"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "id": "d13862e3-bb27-47af-9b58-a9fbf804df71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
      },
      "source": [
        "## Hyperparameter Setting"
      ],
      "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'EPOCHS':80,\n",
        "    'LEARNING_RATE':1e-4,\n",
        "    'BATCH_SIZE':8,\n",
        "    'SEED':41,\n",
        "    'PATIENCE':10,\n",
        "}"
      ],
      "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
      },
      "source": [
        "## Fixed RandomSeed"
      ],
      "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ],
      "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
      },
      "source": [
        "## Data Pre-processing"
      ],
      "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb174705-e5df-442d-b82a-cb17a4e831e6"
      },
      "outputs": [],
      "source": [
        "all_df = pd.read_csv('./train.csv')\n",
        "all_points = h5py.File('./train.h5', 'r')"
      ],
      "id": "bb174705-e5df-442d-b82a-cb17a4e831e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89082ab7-7784-4e91-ad9c-6b9d2174ab91"
      },
      "outputs": [],
      "source": [
        "train_df = all_df.iloc[:int(len(all_df)*0.8)]\n",
        "val_df = all_df.iloc[int(len(all_df)*0.8):]"
      ],
      "id": "89082ab7-7784-4e91-ad9c-6b9d2174ab91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, id_list, label_list, point_list, transforms= Sequence[Callable]):\n",
        "        self.id_list = id_list\n",
        "        self.label_list = label_list\n",
        "        self.point_list = point_list\n",
        "        self.transforms = transforms\n",
        "    def __getitem__(self, index):\n",
        "        image_id = self.id_list[index]\n",
        "        \n",
        "        # h5파일을 바로 접근하여 사용하면 학습 속도가 병목 현상으로 많이 느릴 수 있습니다.\n",
        "        points = self.point_list[str(image_id)][:]\n",
        "        image = self.get_vector(points)\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            image=torch.Tensor(image).unsqueeze(0)\n",
        "            if self.transforms is not None:\n",
        "              image = self.transforms(image)\n",
        "            return image, label\n",
        "        else:\n",
        "            image=torch.Tensor(image).unsqueeze(0)\n",
        "            if self.transforms is not None:\n",
        "              image = self.transforms(image)\n",
        "            return image\n",
        "    \n",
        "    def get_vector(self, points, x_y_z=[16, 16, 16]):\n",
        "        # 3D Points -> [16,16,16]\n",
        "        xyzmin = np.min(points, axis=0) - 0.001\n",
        "        xyzmax = np.max(points, axis=0) + 0.001\n",
        "\n",
        "        diff = max(xyzmax-xyzmin) - (xyzmax-xyzmin)\n",
        "        xyzmin = xyzmin - diff / 2\n",
        "        xyzmax = xyzmax + diff / 2\n",
        "\n",
        "        segments = []\n",
        "        shape = []\n",
        "\n",
        "        for i in range(3):\n",
        "            # note the +1 in num \n",
        "            if type(x_y_z[i]) is not int:\n",
        "                raise TypeError(\"x_y_z[{}] must be int\".format(i))\n",
        "            s, step = np.linspace(xyzmin[i], xyzmax[i], num=(x_y_z[i] + 1), retstep=True)\n",
        "            segments.append(s)\n",
        "            shape.append(step)\n",
        "\n",
        "        n_voxels = x_y_z[0] * x_y_z[1] * x_y_z[2]\n",
        "        n_x = x_y_z[0]\n",
        "        n_y = x_y_z[1]\n",
        "        n_z = x_y_z[2]\n",
        "\n",
        "        structure = np.zeros((len(points), 4), dtype=int)\n",
        "        structure[:,0] = np.searchsorted(segments[0], points[:,0]) - 1\n",
        "        structure[:,1] = np.searchsorted(segments[1], points[:,1]) - 1\n",
        "        structure[:,2] = np.searchsorted(segments[2], points[:,2]) - 1\n",
        "\n",
        "        # i = ((y * n_x) + x) + (z * (n_x * n_y))\n",
        "        structure[:,3] = ((structure[:,1] * n_x) + structure[:,0]) + (structure[:,2] * (n_x * n_y)) \n",
        "\n",
        "        vector = np.zeros(n_voxels)\n",
        "        count = np.bincount(structure[:,3])\n",
        "        vector[:len(count)] = count\n",
        "\n",
        "        vector = vector.reshape(n_z, n_y, n_x)\n",
        "\n",
        "        return vector\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.id_list)"
      ],
      "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mp25Wa3mhz1"
      },
      "outputs": [],
      "source": [
        "training_transform = tio.Compose([\n",
        "    ToCanonical(),\n",
        "    tio.Resize((154,154,154)),\n",
        "    #tio.CropOrPad((154, 128, 80),p=0.5,mask_name='heart_mask',),\n",
        "    #tio.RandomNoise(p=0.5),\n",
        "    #tio.RandomSwap(p=0.5),\n",
        "    #tio.RandomGhosting(num_ghosts=(1,2),p=0.5),\n",
        "    tio.RandomFlip(p=0.5,axes=['LR','AP']),\n",
        "    tio.RandomAffine(p=0.5,degrees=(70)),\n",
        "    ZNormalization(),\n",
        "\n",
        "])\n",
        "validation_transform = tio.Compose([\n",
        "    tio.Resize((154,154,154)),\n",
        "    ZNormalization(),\n",
        "])"
      ],
      "id": "_mp25Wa3mhz1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d880481-1965-499d-9caa-fdfa8526f789"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_df['ID'].values,\n",
        "                              train_df['label'].values,\n",
        "                              all_points,\n",
        "                              transforms=training_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size = CFG['BATCH_SIZE'], \n",
        "                          shuffle=True,\n",
        "                          pin_memory=True,    \n",
        "                          num_workers=4)\n",
        "\n",
        "val_dataset = CustomDataset(val_df['ID'].values, \n",
        "                            val_df['label'].values,\n",
        "                            all_points,\n",
        "                            transforms=validation_transform)\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=CFG['BATCH_SIZE'],\n",
        "                        pin_memory=True,    \n",
        "                        shuffle=False,\n",
        "                        num_workers=4)"
      ],
      "id": "9d880481-1965-499d-9caa-fdfa8526f789"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39962463-032f-490a-a76d-c03991795f38"
      },
      "source": [
        "## Model Define"
      ],
      "id": "39962463-032f-490a-a76d-c03991795f38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym4Xttv3Ii8P"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel,self).__init__()\n",
        "        self.model = EfficientNet3D.from_name(\"efficientnet-b4\", in_channels=1)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.classifier = nn.Linear(1000, 10)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        x = self.SiLU(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "id": "Ym4Xttv3Ii8P"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel,self).__init__()\n",
        "        self.model = EfficientNet3D.from_name(\"efficientnet-b0\", in_channels=1)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.classifier = nn.Linear(1000, 10)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.model(x)\n",
        "        x = self.SiLU(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rN1PXtRN_Rkc"
      },
      "id": "rN1PXtRN_Rkc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ic0wF0V4gZV"
      },
      "source": [],
      "id": "5Ic0wF0V4gZV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
      },
      "source": [
        "## Train"
      ],
      "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prHvBvlDsPmV"
      },
      "outputs": [],
      "source": [
        "\n",
        "use_amp = True\n",
        "save_path='best_model.pt'\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "early_stopping = EarlyStopping(patience = CFG['PATIENCE'], verbose = True, path =save_path )"
      ],
      "id": "prHvBvlDsPmV"
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation(y, labels, teacher_scores, T, alpha):\n",
        "    # distillation loss + classification loss\n",
        "    # y: student\n",
        "    # labels: hard label\n",
        "    # teacher_scores: soft label\n",
        "    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 + alpha) + F.cross_entropy(y,labels) * (1.-alpha)\n",
        "\n",
        "# val loss"
      ],
      "metadata": {
        "id": "Wv6BvX_ACTzW"
      },
      "id": "Wv6BvX_ACTzW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distill_loss_batch(output, target, teacher_output, opt, loss_fn=distillation):\n",
        "    loss_b = loss_fn(output, target, teacher_output, T=20.0, alpha=0.7)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b"
      ],
      "metadata": {
        "id": "LSJQDYLwB2yU"
      },
      "id": "LSJQDYLwB2yU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the metric per mini-batch\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# calculate the loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss_b.item(), metric_b"
      ],
      "metadata": {
        "id": "CfyiZe-LEvbZ"
      },
      "id": "CfyiZe-LEvbZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_epoch(model, loss_func, val_loader, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(val_loader.dataset)\n",
        "\n",
        "    for data, label in tqdm(iter(val_loader)):\n",
        "        data, label = data.float().to(device), label.long().to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, label, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric"
      ],
      "metadata": {
        "id": "CLAbn01VEsVq"
      },
      "id": "CLAbn01VEsVq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
      },
      "outputs": [],
      "source": [
        "def train(student_model,teacher_model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    student_model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    best_score = 0\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        student_model.train()\n",
        "        running_loss = 0.0\n",
        "        running_metric = 0.0\n",
        "        len_data = len(train_loader.dataset)\n",
        "\n",
        "        for data, label in tqdm(iter(train_loader)):\n",
        "            data, label = data.float().to(device), label.long().to(device)\n",
        "\n",
        "            output = student_model(data)\n",
        "            teacher_output = teacher_model(data).detach()\n",
        "            loss_b, metric_b = distill_loss_batch(output, label, teacher_output, loss_fn=distillation, opt=optimizer)\n",
        "            running_loss += loss_b\n",
        "            running_metric_b = metric_b\n",
        "        train_loss = running_loss / len_data\n",
        "        train_metric = running_metric / len_data\n",
        "\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "            \n",
        "        val_loss, val_acc = validation(student_model, criterion, val_loader, device)\n",
        "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss)}] Val Loss : [{val_loss}] Val ACC : [{val_acc}]')\n",
        "        early_stopping(-val_acc, student_model)\n",
        "        if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          break\n"
      ],
      "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "079a36b3-fdc4-478d-ade4-47188329ebcf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    model_preds = []\n",
        "    val_loss = []\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, criterion, val_loader)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    return val_loss, val_metric*100"
      ],
      "id": "079a36b3-fdc4-478d-ade4-47188329ebcf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
      },
      "source": [
        "## Train\n",
        "\n"
      ],
      "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86142d9a-68b7-4d04-8423-49d28025411d"
      },
      "outputs": [],
      "source": [
        "teacher_model = TeacherModel().to(device)\n",
        "teacher_model.load_state_dict(torch.load('/content/drive/MyDrive/data/3d data/models/eff4 154 LR AP 70.pt', map_location=device), strict=False)\n",
        "\n",
        "student_model = StudentModel().to(device)\n",
        "loss_history = {'train': [], 'val': []}\n",
        "metric_history = {'train': [], 'val': []}\n",
        "\n",
        "optimizer = torch.optim.AdamW(params = student_model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "#base_optimizer = torch.optim.SGD  \n",
        "#optimizer = SAM(student_model.parameters(), base_optimizer, lr=CFG[\"LEARNING_RATE\"], momentum=0.9)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.01, last_epoch=-1)\n",
        "\n",
        "train(student_model,teacher_model, optimizer, train_loader, val_loader, scheduler, device)"
      ],
      "id": "86142d9a-68b7-4d04-8423-49d28025411d"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2-fsLzLD0Yf"
      },
      "id": "o2-fsLzLD0Yf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVKW-YGFD0cM"
      },
      "id": "VVKW-YGFD0cM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}